{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37428026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atharva/miniconda3/envs/cpsy-env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098abb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "login(os.getenv('HF_TOKEN'))\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv('OPENROUTER_API_KEY'),\n",
    "    # api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18201ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Um — do you know where the world’s largest ice sheet is located today?\"\n",
    "\n",
    "classifier_input = f'''Please assess what personality best fits the following text. The categories are:  \n",
    "- Formal  \n",
    "- Casual  \n",
    "- Confident  \n",
    "- Hesitant  \n",
    "- Analytical  \n",
    "- Emotional  \n",
    "- Optimistic  \n",
    "- Pessimistic  \n",
    "\n",
    "<text>  \n",
    "{user_input}\n",
    "</text>  \n",
    "\n",
    "Please respond with a single word.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696cf992",
   "metadata": {},
   "source": [
    "### Simple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8938945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='google/gemini-2.5-flash',\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": classifier_input,\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78412aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hesitant\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca21205",
   "metadata": {},
   "source": [
    "### Classifier with logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8fe06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='google/gemini-2.5-flash',\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": classifier_input,\n",
    "        }\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdde2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hesitant\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6547c6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hesitant', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='STOP')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "896d8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = completion.choices[0].logprobs.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03d967af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'H',\n",
       " 'bytes': [72],\n",
       " 'logprob': -4.320199877838604e-07,\n",
       " 'top_logprobs': [TopLogprob(token='H', bytes=[72], logprob=-4.320199877838604e-07),\n",
       "  TopLogprob(token='Cur', bytes=[67, 117, 114], logprob=-15.25),\n",
       "  TopLogprob(token='Cas', bytes=[67, 97, 115], logprob=-15.75),\n",
       "  TopLogprob(token=' hesitant', bytes=[32, 104, 101, 115, 105, 116, 97, 110, 116], logprob=-17.375),\n",
       "  TopLogprob(token='P', bytes=[80], logprob=-17.75)]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0c181bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TopLogprob(token='H', bytes=[72], logprob=-4.320199877838604e-07),\n",
       " TopLogprob(token='Cur', bytes=[67, 117, 114], logprob=-15.25),\n",
       " TopLogprob(token='Cas', bytes=[67, 97, 115], logprob=-15.75),\n",
       " TopLogprob(token=' hesitant', bytes=[32, 104, 101, 115, 105, 116, 97, 110, 116], logprob=-17.375),\n",
       " TopLogprob(token='P', bytes=[80], logprob=-17.75)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0].top_logprobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb9fec",
   "metadata": {},
   "source": [
    "### Classifier with logits – using GitHub models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c974b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_completion(model_input: str, model: str = 'openai/gpt-4.1-mini'): \n",
    "    url = \"https://models.github.ai/inference/chat/completions\"\n",
    "    github_token = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"Authorization\": f\"Bearer {github_token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": model_input\n",
    "            }\n",
    "        ],\n",
    "        \"logprobs\": True, \n",
    "        \"top_logprobs\": 5,\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, json=payload, headers=headers, timeout=30)\n",
    "    completion = json.loads(resp.text)\n",
    "\n",
    "    return completion, resp\n",
    "\n",
    "\n",
    "def print_rate_limits(response):\n",
    "    print(f'total rate limit requests per hour: {response.headers['x-ratelimit-limit-requests']}')\n",
    "    print(f'rate limit requests remaining this hour: {response.headers['x-ratelimit-remaining-requests']}')\n",
    "\n",
    "    print(f'total rate limit tokens per hour: {response.headers['x-ratelimit-limit-tokens']}')\n",
    "    print(f'rate limit tokens remaining this hour: {response.headers['x-ratelimit-remaining-tokens']}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fd8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion, response = get_model_completion(model_input=classifier_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70649bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': [],\n",
       " 'content': 'Hesitant',\n",
       " 'refusal': None,\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = completion['choices'][0]['message']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e8679c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bytes': [72], 'logprob': -9.088346359931165e-07, 'token': 'H'},\n",
       " {'bytes': [67, 97, 115], 'logprob': -14.500000953674316, 'token': 'Cas'},\n",
       " {'bytes': [104, 101, 115], 'logprob': -14.750000953674316, 'token': 'hes'},\n",
       " {'bytes': [32, 104, 101, 115, 105, 116, 97, 110, 116],\n",
       "  'logprob': -20.375,\n",
       "  'token': ' hesitant'},\n",
       " {'bytes': [32, 72, 101, 115], 'logprob': -20.5, 'token': ' Hes'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logprobs = completion['choices'][0]['logprobs']['content']\n",
    "# assert len(all_logprobs) == 1   # ie. the model should respond with a single token\n",
    "\n",
    "all_logprobs[0]['top_logprobs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
